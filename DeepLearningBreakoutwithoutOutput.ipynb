{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linakatabicity/DLModule/blob/main/DeepLearningBreakoutwithoutOutput.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48vkUxJ_fyEL"
      },
      "outputs": [],
      "source": [
        "!pip install gym[atari]\n",
        "!apt-get install -y xvfb x11-utils\n",
        "!pip install pyvirtualdisplay==0.2.*\n",
        "!pip install autorom[accept-rom-license]\n",
        "!pip install --upgrade gym==0.19.0\n",
        "!pip install -U \"ray[rllib]\"==1.6\n",
        "!pip install tensorboardX\n",
        "!pip install --upgrade grpcio "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWSJpsyKqHjH",
        "outputId": "332b5814-aac9-4725-d901-8884c038665a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lq3a8T8rLuk"
      },
      "outputs": [],
      "source": [
        "#to clear tensor board log files\n",
        "!rm -rf  /root/ray_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lppe1DyXSE0Q"
      },
      "outputs": [],
      "source": [
        "from ray.rllib.agents.ppo import PPOTrainer\n",
        "import ray.rllib.agents.dqn as dqn\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from ray import tune\n",
        "import datetime\n",
        "%load_ext tensorboard\n",
        "import tensorflow as tf\n",
        "import tensorboardX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FA_8jdLX1k8"
      },
      "source": [
        "## Render the environment for visual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "QrDAMEe1f8AA",
        "outputId": "840c3eb7-7da2-4dcf-ecb2-7307ec4004e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward 0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "env = gym.make('Breakout-v0')\n",
        "env.reset()\n",
        "for _ in range(100):\n",
        "    plt.imshow(env.render(mode='rgb_array'))\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(env.action_space.sample())\n",
        "\n",
        "    print(\"Reward\", reward)\n",
        "    env.step(action)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPsy8L5hX_Fx"
      },
      "source": [
        "## Code Helper "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLENR8tsiCjI"
      },
      "outputs": [],
      "source": [
        "# Import the RL algorithm (Trainer) we would like to use.\n",
        "\n",
        "\n",
        "def evaluation_fn(result):\n",
        "    return result['episode_reward_mean']\n",
        "\n",
        "\n",
        "def objective_fn(config):   \n",
        "    trainer = dqn.DQNTrainer(config=config)\n",
        "    for i in range(100):\n",
        "      # Perform one iteration of training the policy with DQN\n",
        "      result = trainer.train()\n",
        "      intermediate_score = evaluation_fn(result)\n",
        "      \n",
        "      # Feed the score back back to Tune.\n",
        "      tune.report(iterations=i, mean_reward=intermediate_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpomeZP3YLOZ"
      },
      "source": [
        "## Configure Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdkfPMiiSDCL"
      },
      "outputs": [],
      "source": [
        "\n",
        "config = dqn.DEFAULT_CONFIG.copy()\n",
        "config[\"env\"] = 'Breakout-v0'\n",
        "config[\"dueling\"] = True\n",
        "config[\"double_q\"] = True\n",
        "config[\"gamma\"] = tune.uniform(0, 1)\n",
        "config[\"train_batch_size\"] = tune.grid_search([25,32,62])\n",
        "config['num_gpus'] =  1\n",
        "config['lr'] = 0.001\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UibA0tvNYQVF"
      },
      "source": [
        "## Run Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Baiiegc5OWpy"
      },
      "outputs": [],
      "source": [
        "\n",
        "analysis = tune.run(\n",
        "        objective_fn,\n",
        "        metric=\"mean_reward\",\n",
        "        mode=\"max\",\n",
        "        #stop = {'episode_reward_mean': 20},\n",
        "        num_samples=3,\n",
        "        resources_per_trial={'gpu': 1},\n",
        "        config=config\n",
        "        )\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir  /root/ray_results\n",
        "#print(\"Best hyperparameters found were: \", analysis.best_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yzzTcbZzQga",
        "outputId": "aaf9f42a-f895-498a-d56b-04ca77600b6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters found were:  {'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'gamma': 0.9636508942389949, 'lr': 0.001, 'train_batch_size': 25, 'model': {'_use_default_native_models': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'num_framestacks': 'auto', 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, 'framestack': True}, 'optimizer': {}, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env': 'Breakout-v0', 'observation_space': None, 'action_space': None, 'env_config': {}, 'env_task_fn': None, 'render_env': False, 'record_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'preprocessor_pref': 'deepmind', 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'evaluation_parallel_to_training': False, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 1, 'timesteps_per_iteration': 1000, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'placement_strategy': 'PACK', 'input': 'sampler', 'input_config': {}, 'actions_in_input_normalized': False, 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': None, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, 'simple_optimizer': -1, 'monitor': -1, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'target_network_update_freq': 500, 'buffer_size': 50000, 'replay_sequence_length': 1, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'worker_side_prioritization': False}\n"
          ]
        }
      ],
      "source": [
        "print(\"Best hyperparameters found were: \", analysis.best_config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = dqn.DEFAULT_CONFIG.copy()\n",
        "config[\"env\"] = 'Breakout-v0'\n",
        "config[\"dueling\"] = True\n",
        "config[\"double_q\"] = True\n",
        "config[\"gamma\"] = 0.963651\n",
        "config[\"train_batch_size\"] = 25\n",
        "config['num_gpus'] =  1\n",
        "config['lr'] = 0.001\n",
        "config['timesteps_per_iteration']= 2500\n",
        "\n",
        "config2 = dqn.DEFAULT_CONFIG.copy()\n",
        "config2[\"env\"] = 'Breakout-v0'\n",
        "config2[\"dueling\"] = False\n",
        "config2[\"double_q\"] = True\n",
        "config2[\"gamma\"] = 0.963651\n",
        "config2[\"train_batch_size\"] = 25\n",
        "config2['num_gpus'] =  1\n",
        "config2['lr'] = 0.001\n",
        "config2['timesteps_per_iteration']= 2500\n",
        "\n",
        "config3 = dqn.DEFAULT_CONFIG.copy()\n",
        "config3[\"env\"] = 'Breakout-v0'\n",
        "config3[\"dueling\"] = False\n",
        "config3[\"double_q\"] = True\n",
        "config3[\"gamma\"] = 0.963651\n",
        "config3[\"train_batch_size\"] = 25\n",
        "config3['num_gpus'] =  1\n",
        "config3['lr'] = 0.001\n",
        "config3['timesteps_per_iteration']= 2500\n",
        "\n",
        "\n",
        "config4 = dqn.DEFAULT_CONFIG.copy()\n",
        "config4[\"env\"] = 'Breakout-v0'\n",
        "config4[\"dueling\"] = True\n",
        "config4[\"double_q\"] = True\n",
        "config4['prioritized_replay'] = False\n",
        "config4[\"gamma\"] = 0.963651\n",
        "config4[\"train_batch_size\"] = 25\n",
        "config4['num_gpus'] =  1\n",
        "config4['lr'] = 0.001\n",
        "config4['timesteps_per_iteration']= 2500\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fqRe0rh4YNw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!rm -rf  /root/ray_results\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir  /root/ray_results\n",
        "\n",
        "analysis = tune.run(\n",
        "        objective_fn,\n",
        "        metric=\"mean_reward\",\n",
        "        mode=\"max\",\n",
        "        #stop = {'episode_reward_mean': 20},\n",
        "        num_samples=1,\n",
        "        resources_per_trial={'gpu': 1},\n",
        "        config=config\n",
        "\n",
        "        )\n",
        "\n",
        "analysis2 = tune.run(\n",
        "        objective_fn,\n",
        "        metric=\"mean_reward\",\n",
        "        mode=\"max\",\n",
        "        #stop = {'episode_reward_mean': 20},\n",
        "        num_samples=1,\n",
        "        resources_per_trial={'gpu': 1},\n",
        "        config=config2\n",
        "\n",
        "        )\n",
        "analysis3 = tune.run(\n",
        "        objective_fn,\n",
        "        metric=\"mean_reward\",\n",
        "        mode=\"max\",\n",
        "        #stop = {'episode_reward_mean': 20},\n",
        "        num_samples=1,\n",
        "        resources_per_trial={'gpu': 1},\n",
        "        config=config3\n",
        "\n",
        "        )\n",
        "analysis4 = tune.run(\n",
        "        objective_fn,\n",
        "        metric=\"mean_reward\",\n",
        "        mode=\"max\",\n",
        "        #stop = {'episode_reward_mean': 20},\n",
        "        num_samples=1,\n",
        "        resources_per_trial={'gpu': 1},\n",
        "        config=config4\n",
        "\n",
        "        )\n"
      ],
      "metadata": {
        "id": "T7mX_jGnWpyH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DeepLearningBreakoutwithoutOutput.ipynb",
      "provenance": [],
      "mount_file_id": "1JNa254uOBqfA1O5fzhWceLy7EaVuOOyy",
      "authorship_tag": "ABX9TyNtaDzvBHmtoz/V7TmZYSzY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}